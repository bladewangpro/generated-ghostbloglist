<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on prometheus</title><link>https://new.halfrost.com/categories/machine-learning/</link><description>Recent content in Machine Learning on prometheus</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>halfrost</copyright><lastBuildDate>Thu, 05 Apr 2018 18:36:00 +0000</lastBuildDate><atom:link href="https://new.halfrost.com/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Machine Learning 机器学习笔记</title><link>https://new.halfrost.com/machine_learning_contents/</link><pubDate>Thu, 05 Apr 2018 18:36:00 +0000</pubDate><guid>https://new.halfrost.com/machine_learning_contents/</guid><description>目录 前言 第一周：Welcome 1.1 What is Machine Learning? 1.2 Linear Regression with One Variable 第二周：Linear Regression with Multiple Variables 2.1 Multivariate Linear Regression 2.2 Computing Parameters Analytically 2.3 Octave/Matlab Tutorial 第三周：Logistic Regression 3.1 Logistic Regression 3.2 Regularization 第四周：Neural Networks: Representation 4.1 Neural Networks Representation 第五周：Neural Networks: Learning 5.1 Neural Networks Learning 5.2 Backpropagation in Practice 第六周：Advice for Applying Machine Learning 6.</description></item><item><title>机器学习应用 —— Photo OCR</title><link>https://new.halfrost.com/application_example_photo_ocr/</link><pubDate>Wed, 04 Apr 2018 18:31:00 +0000</pubDate><guid>https://new.halfrost.com/application_example_photo_ocr/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Application_Photo_OCR.ipynb
一. Photo OCR 1. Problem Description and Pipeline 问题描述 图像文字识别应用所作的事是，从一张给定的图片中识别文字。这比从一份扫描文档中识别文字要复杂的多。
为了完成这样的工作，需要采取如下步骤：
文字侦测（Text detection）——将图片上的文字与其他环境对象分离开来 字符切分（Character segmentation）——将文字分割成一个个单一的字符 字符分类（Character classification）——确定每一个字符是什么 可以用任务流程图来表达这个问题，每一项任务可以由一个单独的小队来负责解决：
2. Sliding Windows 滑动窗口 滑动窗口是一项用来从图像中抽取对象的技术。假使我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁，然后将剪裁得到的切片交给模型，让模型判断是否为行人，然后在图片上滑动剪裁区域重新进行剪裁，将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。
一旦完成后，我们按比例放大剪裁的区域，再以新的尺寸对图片进行剪裁，将新剪裁的切片按比例缩小至模型所采纳的尺寸，交给模型进行判断，如此循环。
滑动窗口技术也被用于文字识别，首先训练模型能够区分字符与非字符，然后，运用滑动窗口技术识别字符，一旦完成了字符的识别，我们将识别得出的区域进行一些扩展，然后将重叠的区域进行合并。接着我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。下图中绿色的区域是经过这些步骤后被认为是文字的区域，而红色的区域是被忽略的。
以上便是文字侦测阶段。 下一步是训练一个模型来完成将文字分割成一个个字符的任务，需要的训练集由单个字符的图片和两个相连字符之间的图片来训练模型。
模型训练完后，我们仍然是使用滑动窗口技术来进行字符识别。
以上便是字符切分阶段。 最后一个阶段是字符分类阶段，利用神经网络、支持向量机或者逻辑回归算法训练一个分类器即可。
3. Getting Lots of Data and Artificial Data 人工合成数据 在字符识别阶段，为了更好的完成分类识别任务，我们就需要给系统提供尽可能多的训练图像，如果我们手头上拥有的图像不多，就需要人工合成更多的数据。例如，我们可以收集不同的字体，并为每种字体的每个字符加上随机背景，这样就可以人工扩展大量的字符图像：
另外，也可以通过扭曲字符形状来合成新数据，这也会帮助机器更好地处理发生过形态变化的图像：
但是，为数据加上随机噪声一般不会提升模型训练质量：
4. ceiling analysis 上限分析 在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。
回到我们的文字识别应用中，我们的流程图如下：
所谓上限分析，就是我们假定某个组件及其前面组件的精度都达到了 100%，即该组件完美地完成了任务，达到了上限，那么此时整个系统的精度能提升多少 。例如，假定整个系统的精度是 72%，我们令文本检测的精度是 100%（比如人工利用 PS 来定位图片中的文本框），此时，整个系统的精度能提升到 89%。即，如果我们付出足够多的精力来优化文本检测，那么理想情况下，能将系统的精度提升 17%：</description></item><item><title>大规模机器学习中如何优化算法？</title><link>https://new.halfrost.com/large_scale_machine_learning/</link><pubDate>Tue, 03 Apr 2018 18:28:00 +0000</pubDate><guid>https://new.halfrost.com/large_scale_machine_learning/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Large_Scale_Machine_Learning.ipynb
一. Gradient Descent with Large Datasets 如果我们有一个低方差的模型，增加数据集的规模可以帮助你获得更好的结果。我们应该怎样应对一个有100万条记录的训练集？
以线性回归模型为例，每一次梯度下降迭代，我们都需要计算训练集的误差的平方和，如果我们的学习算法需要有20次迭代，这便已经是非常大的计算代价。
首先应该做的事是去检查一个这么大规模的训练集是否真的必要，也许我们只用1000个训练集也能获得较好的效果，我们可以绘制学习曲线来帮助判断。
二. Advanced Topics 1. 批量梯度下降法（Batch gradient descent） 拥有了大数据，就意味着，我们的算法模型中得面临一个很大的 m 值。回顾到我们的批量梯度下降法：
重复直到收敛：
$$\theta_j=\theta_j-\alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_j,\;\;\;\;for\;\;j=0,\cdots,n$$
可以看到，每更新一个参数 $\theta_j$ ，我们都不得不遍历一遍样本集，在 m 很大时，该算法就显得比较低效。但是，批量梯度下降法能找到全局最优解：
2. 随机梯度下降法（Stochastic gradient descent） 针对大数据集，又引入了随机梯度下降法，该算法的执行过程为：
重复直到收敛：
$$ \begin{align*} for\;\;\;i&amp;amp;=1,\cdots,m:\
\theta_j&amp;amp;=\theta_j-\alpha(h_\theta(x^{(i)})-y^{(i)})x^{(i)}_j,\;\;\;\;for\;\;j=0,\cdots,n\
\end{align*} $$
相较于批量梯度下降法，随机梯度下降法每次更新 $\theta_j$ 只会用当前遍历的样本。虽然外层循环仍需要遍历所有样本，但是，往往我们能在样本尚未遍历完时就已经收敛，因此，面临大数据集时，随机梯度下降法性能卓越。
上图反映了随机梯度下降法找寻最优解的过程，相较于批量梯度下降法，随机梯度下降法的曲线就显得不是那么平滑，而是很曲折了，其也倾向于找到局部最优解而不是全局最优解。因此，我们通常需要绘制调试曲线来监控随机梯度的工作过程是否正确。例如，假定误差定义为 $cost(\theta,(x^{(i)},y^{(i)}))=\frac{1}{2}(h_\theta(x^{(i)})-y^{(i)})^2$，则每完成 1000 次迭代，即遍历了 1000 个样本，我们求取平均误差并进行绘制，得到误差随迭代次数的变化曲线：</description></item><item><title>推荐系统中的协同过滤和低秩矩阵分解</title><link>https://new.halfrost.com/recommender_systems/</link><pubDate>Mon, 02 Apr 2018 18:25:00 +0000</pubDate><guid>https://new.halfrost.com/recommender_systems/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Recommender_Systems.ipynb
一. Predicting Movie Ratings 以预测第3部电影第1个用户可能评的分数为例子。
首先我们用 $x_1$ 表示爱情浪漫电影类型， $x_2$ 表示动作片类型。上图左表右侧则为每部电影对于这两个分类的相关程度。我们默认 $x_0=1$ 。则第一部电影与两个类型的相关程度可以这样表示： $x^{(3)}=\left[ \begin{array}{ccc}1 \0.99 \0 \end{array} \right]$ 。然后用 $\theta^{(j)}$ 表示第 j 个用户对于该种类电影的评分。这里我们假设已经知道（详情下面再讲） $\theta^{(1)}=\left[ \begin{array}{ccc}0 \5 \0 \end{array} \right]$ ，那么我们用 $(\theta^{(j)})^Tx^{(i)}$ 即可计算出测第3部电影第1个用户可能评的分数。这里计算出是4.95。
1. 目标优化 为了对用户 j 打分状况作出最精确的预测，我们需要：
$$\min_{(\theta^{(j)})}=\frac{1}{2}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}$$
计算出所有的 $\theta$ 为：
$$J(\theta^{(1)},\cdots,\theta^{(n_u)})=\min_{(\theta^{(1)},\cdots,\theta^{(n_u)})}=\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}$$
与前面所学线性回归内容的思路一致，为了计算出 $J(\theta^{(1)},\cdots,\theta^{(n_u)})$，使用梯度下降法来更新参数：
更新偏置（插值）：
$$\theta^{(j)}_0=\theta^{(j)}0-\alpha \sum{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_0$$
更新权重：
$$\theta^{(j)}_k=\theta^{(j)}k-\alpha \left( \sum{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_k+\lambda \theta^{(j)}_k \right),;;; k \neq 0$$</description></item><item><title>机器学习中的异常检测问题</title><link>https://new.halfrost.com/anomaly_detection/</link><pubDate>Sun, 01 Apr 2018 18:12:00 +0000</pubDate><guid>https://new.halfrost.com/anomaly_detection/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Anomaly_Detection.ipynb
一. Density Estimation 密度估计 假如要更为正式定义异常检测问题，首先我们有一组从 $x^{(1)}$ 到 $x^{(m)}$ m个样本，且这些样本均为正常的。我们将这些样本数据建立一个模型 p(x) ， p(x) 表示为 x 的分布概率。
那么假如我们的测试集 $x_{test}$ 概率 p 低于阈值 $\varepsilon$ ，那么则将其标记为异常。
异常检测的核心就在于找到一个概率模型，帮助我们知道一个样本落入正常样本中的概率，从而帮助我们区分正常和异常样本。高斯分布（Gaussian Distribution）模型就是异常检测算法最常使用的概率分布模型。
1. 高斯分布 假如 x 服从高斯分布，那么我们将表示为： $x\sim N(\mu,\sigma^2)$ 。其分布概率为：
$$p(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})$$
其中 $\mu$ 为期望值（均值）， $\sigma^2$ 为方差。
其中，期望值 $\mu$ 决定了其轴的位置，标准差 $\sigma$ 决定了分布的幅度宽窄。当 $\mu=0,\sigma=1$ 时的正态分布是标准正态分布。
期望值：$$\mu=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}}$$
方差： $$\sigma^2=\frac{1}{m}\sum_{i=1}^{m}{(x^{(i)}-\mu)}^2$$
假如我们有一组 m 个无标签训练集，其中每个训练数据又有 n 个特征，那么这个训练集应该是 m 个 n 维向量构成的样本矩阵。</description></item><item><title>PCA 与降维</title><link>https://new.halfrost.com/dimensionality_reduction/</link><pubDate>Sat, 31 Mar 2018 18:09:00 +0000</pubDate><guid>https://new.halfrost.com/dimensionality_reduction/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Dimensionality_Reduction.ipynb
一. Motivation 我们很希望有足够多的特征（知识）来保准学习模型的训练效果，尤其在图像处理这类的任务中，高维特征是在所难免的，但是，高维的特征也有几个如下不好的地方：
学习性能下降，知识越多，吸收知识（输入），并且精通知识（学习）的速度就越慢。 过多的特征难于分辨，你很难第一时间认识某个特征代表的意义。 特征冗余，如下图所示，厘米和英尺就是一对冗余特征，他们本身代表的意义是一样的，并且能够相互转换。 我们使用现在使用了一条绿色直线，将各个样本投影到该直线，那么，原来二维的特征 x=(厘米，英尺) 就被降低为了一维 x=(直线上的相对位置)
而在下面的例子中，我们又将三维特征投影到二位平面，从而将三维特征降到了二维：
特征降维的一般手段就是将高维特征投影到低维空间。
二. Principal Component Analysis 主成分分析 PCA，Principle Component Analysis，即主成分分析法，是特征降维的最常用手段。顾名思义，PCA 能从冗余特征中提取主要成分，在不太损失模型质量的情况下，提升了模型训练速度。
如上图所示，我们将样本到红色向量的距离称作是投影误差（Projection Error）。以二维投影到一维为例，PCA 就是要找寻一条直线，使得各个特征的投影误差足够小，这样才能尽可能的保留原特征具有的信息。
假设我们要将特征从 n 维度降到 k 维：PCA 首先找寻 k 个 n 维向量，然后将特征投影到这些向量构成的 k 维空间，并保证投影误差足够小。下图中中，为了将特征维度从三维降低到二位，PCA 就会先找寻两个三维向量 $\mu^{(1)},\mu^{(2)}$ ，二者构成了一个二维平面，然后将原来的三维特征投影到该二维平面上：
1. 区别 PCA 和 线性回归的区别是：
线性回归找的是垂直于 X 轴距离最小值，PCA 找的是投影垂直距离最小值。</description></item><item><title>无监督学习</title><link>https://new.halfrost.com/unsupervised_learning/</link><pubDate>Fri, 30 Mar 2018 18:05:00 +0000</pubDate><guid>https://new.halfrost.com/unsupervised_learning/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Unsupervised_Learning.ipynb
一. Clustering 1. 定义 从本节开始，将正式进入到无监督学习（Unsupervised Learning）部分。无监督学习，顾名思义，就是不受监督的学习，一种自由的学习方式。该学习方式不需要先验知识进行指导，而是不断地自我认知，自我巩固，最后进行自我归纳，在机器学习中，无监督学习可以被简单理解为不为训练集提供对应的类别标识（label），其与有监督学习的对比如下：
有监督学习（Supervised Learning）下的训练集：
$$\left{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(m)},y^{(m)}) \right}$$
无监督学习（Unsupervised Learning）下的训练集：
$$\left{ (x^{(1)}),(x^{(2)}),(x^{(3)}),\cdots,(x^{(m)}) \right}$$
在有监督学习中，我们把对样本进行分类的过程称之为分类（Classification），而在无监督学习中，我们将物体被划分到不同集合的过程称之为聚类（Clustering）。聚这个动词十分精确，他传神地描绘了各个物体自主地想属于自己的集合靠拢的过程。
在聚类中，我们把物体所在的集合称之为簇（cluster）。
2. K-Means 在聚类问题中，我们需要将未加标签的数据通过算法自动分成有紧密关系的子集。那么K均值聚类算法（K-mean）是现在最为广泛使用的聚类方法。
我们执行K均值聚类算法是这样的。首先随机选择两个点，这两个点叫做聚类中心（cluster centroids），也就是图中红色和蓝色的交叉。K均值聚类 一个迭代的方法，它要做两件事，一件是簇分配，另一件是移动聚类中心。
在K均值聚类算法的每次循环里面，第一步要进行的是簇分配。首先要历遍所有的样本，也就是上图中每一个绿色的点，然后根据每一个点是更接近红色的这个中心还是蓝色的这个中心，将每一个数据点分配到两个不同的聚类中心。
例如第一次我们随机定的两个中心点和其簇分配如下图所示：
第二步要做的自然是要移动聚类中心。我们需要将两个中心点移动到刚才我们分成两类的数据各自的均值处。那么所要做的就是找出所有红色的点计算出他们的均值，然后把红色叉叉移动到该均值处，蓝色叉叉亦然。
然后通过不断重复上述两个步骤，通过不断迭代直到其聚类中心不变，那么也就是说K均值聚类已经收敛了，我们就可以从该数据中找到两个最有关联的簇了。其过程大概如下图所示：
K均值聚类算法有两个输入：一个是参数K，也就是你想从数据中聚类出簇的个数。另一个就是只有x没有y的训练集。
以下是 K 均值聚类算法的过程。
第一步是随机初始化K个聚类中心，记做： $\mu_1, \mu_2,\cdots,\mu_k$ 。
第二个大部分就是进行迭代。其中第一个循环是：对于每个训练样本 ，我们用变量 $c^{(i)}$ 表示在 K 个聚类中心里面最接近 $x^{(i)}$ 那个中心的下标。我们可以通过 $min_k||x^{(i)}-\mu_k||$ 进行计算。第二个循环是：移动聚类中心。将 $\mu_k$ 也就是中心点的值 = 刚才我们分好的簇的均值。</description></item><item><title>初探支持向量机</title><link>https://new.halfrost.com/support_vector_machines/</link><pubDate>Thu, 29 Mar 2018 17:47:00 +0000</pubDate><guid>https://new.halfrost.com/support_vector_machines/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Support_Vector_Machines.ipynb
一. 引子 在逻辑回归中，我们的预测函数为：
$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$$
对于每一个样本 (x,y) 而言（注意是每一个），其代价函数为：
$$ \begin{align*} J(\theta)&amp;amp;=-(ylogh_\theta(x)+(1-y)log(1-h_\theta((x)))\
&amp;amp;=-ylog\frac{1}{1+e^{-\theta^Tx}}-(1-y)log(1-\frac{1}{1+e^{-\theta^Tx}}) \end{align*}\
$$
那么当 y=1 的时候， $J(\theta)=-ylog\frac{1}{1+e^{-\theta^Tx}}$ ，其代价函数的图像入左下图所示。
当 y=0 的时候， $J(\theta)=-(1-y)log(1-\frac{1}{1+e^{-\theta^Tx}})$ ，其代价函数的图像入右下图所示。
对于支持向量机而言，
$y=1$ 的时候：
$$cost_1(\theta^Tx^{(i)})=(-logh_\theta(x^{(i)}))$$
$y=0$ 的时候：
$$cost_0((\theta^Tx^{(i)})=((-log(1-h_\theta(x^{(i)})))$$
当 y=1 时，随着 z 取值变大，预测代价变小，因此，逻辑回归想要在面对正样本 y=1 时，获得足够高的预测精度，就希望 $z= \theta^Tx\gg 0 $ 。而 SVM 则将上图的曲线拉直为下图中的折线，构成了 y=1 时的代价函数曲线 $cost_1(z)$ ：
当 y=1 时，为了预测精度足够高，SVM 希望 $\theta^Tx\geqslant 1$ 。</description></item><item><title>设计一个机器学习系统需要考虑哪些方面？</title><link>https://new.halfrost.com/machine_learning_system_design/</link><pubDate>Wed, 28 Mar 2018 17:38:00 +0000</pubDate><guid>https://new.halfrost.com/machine_learning_system_design/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Machine_Learning_System_Design.ipynb
一. Building a Spam Classifier 垃圾邮件分类就是一个 0/1 分类问题，可以用逻辑回归完成，这里不再重复介绍逻辑回归的过程了，我们考虑如何降低分类错误率：
尽可能的扩大数据样本：Honypot 做了这样一件事，把自己包装成一个对黑客极具吸引力的机器，来诱使黑客进行攻击，就像蜜罐（honey pot）吸引密封那样，从而记录攻击行为和手段。 添加更多特征：例如我们可以增加邮件的发送者邮箱作为特征，可以增加标点符号作为特征（垃圾邮件总会充斥了？，！等吸引眼球的标点）。 预处理样本：正如我们在垃圾邮件看到的，道高一尺，魔高一丈，垃圾邮件的制造者也会升级自己的攻击手段，如在单词拼写上做手脚来防止邮件内容被看出问题，例如把 medicine 拼写为 med1cinie 等。因此，我们就要有手段来识别这些错误拼写，从而优化我们输入到逻辑回归中的样本。 假如我们要用机器学习解决一个问题，那么最好的实践方法就是：
1.建立一个简单的机器学习系统，用简单的算法快速实现它。
2.通过画出学习曲线，以及检验误差，来找出我们的算法是否存在高偏差或者高方差的问题，然后再通过假如更多的训练数据、特征变量等等来完善算法。
3.误差分析。例如在构建垃圾邮件分类器，我们检查哪一类型的邮件或者那些特征值总是导致邮件被错误分类，从而去纠正它。当然，误差的度量值也是很重要的，例如我们可以将错误率表示出来，用来判断算法的优劣。
二. Handling Skewed Data 评估一个模型的好坏，通常使用误差分析可视化，即把预测的准确率（Accuracy）显示出来，其实这样是有缺陷的。这种误差度量又被称为偏斜类（Skewed Classes）问题。
举个例子：假如我们做癌症分析，最后得出该算法只有1%的误差，也就是说准确率达到了99% 。这样看起来99%算是非常高的了，但是我们发现在训练集里面只有0.5%的患者患有癌症，那么这1%的错误率就变得那么准确了。我们再举个极端一点的例子，无论输入是什么，所有预测输出的数据都为0（也就是非癌症），那么我们这里的正确率是99.5%，但是这样的判断标准显然不能体现分类器的性能。
这是因为两者的数据相差非常大，在这里因为癌症的样本非常少，所以导致了预测的结果就会偏向一个极端，我们把这类的情况叫做偏斜类（Skewed Classes）问题。
所以我们需要另一种的评估方法，其中一种评估度量值叫做查准率（Precision）和召回率（Recall）。
建立一个2 x 2的表格，横坐标为真实值，纵坐标为预测值，表格单元1-4分别代表：预测准确的正样本（True positive）、预测错误的正样本（False positive）、预测错误的负样本（False negative）、预测正确的负样本（True negative）。
查准率（Precision）= 预测准确的正样本（True positive）/预测的正样本（predicted positive）,而其中预测的正样本自然就包括了 预测准确的正样本+ 预测错误的正样本。
$$Precision=\frac{True;positive}{Predicated;as;positive }=\frac{True;positive}{True;positive+False;positive}$$</description></item><item><title>机器学习算法评估</title><link>https://new.halfrost.com/advice_for_applying_machine_learning/</link><pubDate>Tue, 27 Mar 2018 17:28:00 +0000</pubDate><guid>https://new.halfrost.com/advice_for_applying_machine_learning/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Advice_for_Applying_Machine_Learning.ipynb
一. Evaluating a Learning Algorithm 想要降低预测误差，即提高预测精度，我们往往会采用这些手段：
采集更多的样本
错误的认为样本越多越好，其实数据多并不是越好。
降低特征维度
降维可能去掉了有用的特征。
采集更多的特征
增加了计算负担，也可能导致过拟合。
进行高次多项式回归
过高的多项式可能造成过拟合。
调试正规化参数 $\lambda$,增大或者减少 $\lambda$
增大或者减少都是凭感觉。
有这么多种解决办法我们怎么知道是哪一种呢？很多人选择这些方法的标准就是凭感觉随便选择一种，然后花很长的时间最后发现是没用的，走上了不归路。所以下面我们介绍一我们需要一种简单有效的办法，我们将其称为机器学习算法诊断（Machine learning diagnostic）。
1. Evaluating a Hypothesis 评价假设函数 首先我们要评估的是我们的假设函数（Hypothesis）。当我们选择特征值或者参数来使训练集误差最小化，但是我们会遇到过拟合的问题，推广到新的训练集就不再使用了。而且当特征量很多的时候，我们就不能将 $J(\theta)$ 可视化看出其是否随着迭代次数而下降了。所以我们采用以下的方法来评估我们的假设函数：
假设有 10 组数据，随机把 70% 做为训练集，剩下的 30% 做为测试集。训练集和测试集尽量保证是随机排列。
接下来：</description></item><item><title>神经网络反向传播实践</title><link>https://new.halfrost.com/backpropagation_in_practice/</link><pubDate>Mon, 26 Mar 2018 08:35:00 +0000</pubDate><guid>https://new.halfrost.com/backpropagation_in_practice/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Backpropagation_in_Practice.ipynb
一. Backpropagation in Practice 为了利用梯度下降的优化算法，需要用到 fminunc 函数。其输入的参数是 $\theta$ ，函数的返回值是代价函数 jVal 和导数值 gradient。然后将返回值传递给高级优化算法 fminunc，然后输出为输入值 @costFunction，以及 $\theta$ 值的初始值。
其中参数 $\Theta_1,\Theta_2,\Theta_3,\cdots$ 和 $D^{(1)},D^{(2)},D^{(3)},\cdots$ 都为矩阵，那么为了能调用 fminunc 函数，我们要将其变成向量，
假如我们 $\Theta_1,\Theta_2,\Theta_3$ 参数和 $D^{(1)},D^{(2)},D^{(3)}$ 参数，Theta1 是 $10 * 11$，Theta2 是 $10 * 11$，Theta3 是 $1 * 11$。
% 打包成一个向量 thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ] deltaVector = [ D1(:); D2(:); D3(:) ] % 解包还原 Theta1 = reshape(thetaVector(1:110),10,11) Theta2 = reshape(thetaVector(111:220),10,11) Theta3 = reshape(thetaVector(221:231),1,11) 所以套路是：</description></item><item><title>神经网络反向传播算法推导</title><link>https://new.halfrost.com/neural_networks_learning/</link><pubDate>Sun, 25 Mar 2018 08:33:00 +0000</pubDate><guid>https://new.halfrost.com/neural_networks_learning/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb
一. Cost Function and Backpropagation 1. Cost Function 假设训练集中有 m 个训练样本，$\begin{Bmatrix} (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \cdots ,(x^{(m)},y^{(m)}) \end{Bmatrix}$，L 表示神经网络的总层数 Layer，用 $S_{l}$ 表示第 L 层的单元数(神经元的数量)，但是不包括第 L 层的偏差单元(常数项)。令 K 为输出层的单元数目，即 最后一层的单元数。
符号约定：
$z_i^{(j)}$ = 第 $j$ 层的第 $i$ 个节点（神经元）的“计算值” $a_i^{(j)}$ = 第 $j$ 层的第 $i$ 个节点（神经元）的“激活值” $\Theta^{(l)}{i,j}$ = 映射第 $l$ 层到第 $l+1$ 层的权值矩阵的第 $i$ 行第 $j$ 列的分量 $L$ = 神经网络总层数（包括输入层、隐层和输出层） $s_l$ = 第 $l$ 层节点（神经元）个数，不包括偏移量节点。 $K$ = 输出节点个数 $h{\theta}(x)_k$ = 第 $k$ 个预测输出结果 $x^{(i)}$ = 第 $i$ 个样本特征向量 $x^{(i)}_k$ = 第 $i$ 个样本的第 $k$ 个特征值 $y^{(i)}$ = 第 $i$ 个样本实际结果向量</description></item><item><title>初探神经网络</title><link>https://new.halfrost.com/neural_networks_representation/</link><pubDate>Sat, 24 Mar 2018 08:27:00 +0000</pubDate><guid>https://new.halfrost.com/neural_networks_representation/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Representation.ipynb
一. Motivations 假如我们用之前的逻辑回归解决以下分类问题：
我们需要构造一个有很多项的非线性的逻辑回归函数。当只有两个特征量的时候，这还算比较简单的，但是假如我们有100个特征量呢？我们只考虑二阶项的话，其二阶项的个数大约是 $\frac{n^2}{2}$ 。假如我们要包含所有的二阶项的话这样看起来不是一个好办法，因为项数实在太多运算量也很多，而且最后结果往往容易造成过拟合。当然我们只是考虑了二阶项，考虑二阶项以上的就更多了。
当初始特征个数 n 增大时，这些高阶多项式项数将以几何级数上升，特征空间也会随之急剧膨胀 。所以当特征个数 n比较大的时候，用这个方法建立分类器并不是一个好的做法。
而对于大多数的机器学习问题， n 一般是比较大的。
对一个拥有很多特征的复杂数据集进行线性回归是代价很高的。比如我们对 50 * 50 像素的黑白图分类，我们就拥有了 2500 个特征。如果我们还要包含所有二次特征，复杂度为 $O(n^{2}/2)$，也就是说一共要有 $2500^{2}/2=3125000$ 个特征。这样计算的代价是高昂的。
人工神经网络是对具有很多特征的复杂问题进行机器学习的一种方法。
二. Neural Networks 人工神经网络是对生物神经网络的一种简化的模拟。那么，我们先从生物中的神经元入手，进而了解神经网络的工作方式。
用一个简单的模型来模拟神经元的工作，我们将神经元模拟成一个逻辑单元：
$x_{1},x_{2},x_{3}$ 可以将其看成输入神经树突，黄色的圆圈则可以看成中心处理器细胞核， $h_\theta(x)$ 则可看成输出神经轴突。因为这里是逻辑单元，所以我们的输出函数为： $h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$ 。一般我们把这称为一个有 s 型函数（逻辑函数）作为激励的人工神经元。
那么神经网络其实就是这些神经元组合在一起的集合，如下图：
左边第一层 Layer1 被称为输入层。在输入层我们输入我们的特征项 $x_{1},x_{2},x_{3}$ 。
右边最后一层被称为输出层。输出函数为： $h_\Theta(x)$ 。
中间这层被称为隐藏层。</description></item><item><title>什么是正则化？</title><link>https://new.halfrost.com/regularization/</link><pubDate>Fri, 23 Mar 2018 08:16:00 +0000</pubDate><guid>https://new.halfrost.com/regularization/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb
一. Solving the Problem of Overfitting 考虑从 $x \in \mathbb{R}$ 预测 y 的问题。下面最左边的图显示了将 $y =\theta_{0}+\theta_{1}x$ 拟合到数据集的结果。我们看到这些数据并不是直线的，所以这个数据并不是很好。
相反，如果我们添加了一个额外的特征 x2，并且拟合 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}$，那么我们获得的数据稍微更适合,如上图。
但是并不是添加的多项式越多越好。但是，添加太多特征也是一个危险：最右边的数字是拟合五阶多项式 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}+\theta_{5}x^{5} $ 的结果。我们看到即使拟合曲线完美地传递了数据，我们也不会认为这是一个很好的预测，上图最右边的图就是过度拟合的例子。
上图最右边的图也称有高方差。如果我们拟合一个高阶多项式，有过度的特征，并且这个假设函数能拟合几乎所有的数据，这就面临可能的函数太过于庞大，变量太多的问题。我们没有足够的数据去约束它，来获得一个好的假设函数，这就是过度拟合。
欠拟合或高偏倚是当我们的假设函数h的形式很难与数据的趋势作图时。它通常是由一个功能太简单或功能太少造成的。另一方面，过度拟合或高度方差是由适合现有数据的假设函数引起的，但不能很好地预测新数据。它通常是由一个复杂的函数造成的，它会产生大量与数据无关的不必要的曲线和角度。
这个术语适用于线性和逻辑回归。解决过度配合问题有两个主要选项：
1. 减少特征的数量： 手动选择要保留的特征，哪些变量更为重要，哪些变量应该保留，哪些应该舍弃。 使用模型选择算法（稍后在课程中学习），算法会自动选择哪些特征变量保留，哪些舍弃。 缺点是舍弃了一些特征以后，也就舍弃了一些问题的关键信息。
2. 正则化 保留所有的特征，但减少参数 $\theta_{j}$ 的大小或者减少量级。 当有很多个特征的时候，并且每个特征都会对最终预测值产生影响，正则化可以保证运作良好。 正则化目的是尽量去简化这个假设模型。因为这些参数都接近0的时候，越简单的模型也被证明越不容易出现过拟合的问题。
减少一些数量级的特征，加一些“惩罚”项(为了使代价函数最小，乘以 1000 就是惩罚)。
代价函数：
$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{2m} \left [ \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 + \lambda \sum_{i = 1}^{m} \theta_{j}^{2} \right ]$$</description></item><item><title>逻辑回归</title><link>https://new.halfrost.com/logistic_regression/</link><pubDate>Thu, 22 Mar 2018 08:00:00 +0000</pubDate><guid>https://new.halfrost.com/logistic_regression/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Logistic_Regression.ipynb
一. Classification and Representation 要尝试分类，一种方法是使用线性回归，并将所有大于0.5的预测值映射为1，将小于0.5的所有预测值映射为0.但是，此方法效果不佳，因为分类实际上不是线性函数。 分类问题就像回归问题一样，除了我们现在想要预测的值只有少数离散值。
线性回归用来解决分类问题，通常不是一个好主意。
我们解决分类问题，忽略y是离散值，并使用我们的旧线性回归算法来尝试预测给定的x。但是，构建这种方法性能很差的示例很容易。直观地说，当知道$y\in \begin{Bmatrix} 0,1 \end{Bmatrix}$时，$h_{\theta}(x)$ 取大于1或小于0的值也是没有意义的。为了解决这个问题，让我们改变我们的假设 $h_{\theta}(x)$ 的形式以满足 $0\leqslant h_{\theta}(x)\leqslant 1$。这是通过将 $\theta^{T}x$ 插入 Logistic 函数来完成的：
$$g(x) = \frac{1}{1+e^{-x}}$$
上式称为 Sigmoid Function 或者 Logistic Function
令 $h_{\theta}(x) = g(\theta^{T}x)$,$z = \theta^{T}x$,则:
$$g(x) = \frac{1}{1+e^{-\theta^{T}x}}$$
这里显示的函数$g(x)$将任何实数映射到（0,1）区间，使得它可用于将任意值函数转换为更适合分类的函数。
决策边界不是训练集的属性，而是假设本身及其参数的属性。
二. Logistic Regression Model 1. Cost Function 之前定义的代价函数：</description></item><item><title>Octave Matlab 教程</title><link>https://new.halfrost.com/octave_matlab_tutorial/</link><pubDate>Thu, 22 Mar 2018 07:56:00 +0000</pubDate><guid>https://new.halfrost.com/octave_matlab_tutorial/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Octave_Matlab_Tutorial.ipynb
一. Basic Operations 基本操作 在 matlab 中，%是注释符号。基础的数学运算有以下这些：
1 + 2 %加 5 - 6 %减 7 * 4 %乘 9 / 3 %除 6 ^ 4 %幂指数 log(20) %对数运算 exp(30) %指数运算 abs(-2) %绝对值运算 1. 逻辑运算： 1 == 2 %判断是否相等 ans = 0 %false -------------------------------------------------------------------------------------------- 1 ~= 2 % ~= 是 ！= 的意思，判断是否不相等 ans = 1 %True -------------------------------------------------------------------------------------------- 1 &amp;amp;&amp;amp; 0 %逻辑 AND （和运算） ans = 0 -------------------------------------------------------------------------------------------- 1 || 0 %逻辑 OR（或运算） ans = 1 -------------------------------------------------------------------------------------------- xor(1,0) %异或运算 ans = 1 -------------------------------------------------------------------------------------------- 2.</description></item><item><title>计算参数分析 —— 正规方程法</title><link>https://new.halfrost.com/computing_parameters_analytically/</link><pubDate>Wed, 21 Mar 2018 07:50:00 +0000</pubDate><guid>https://new.halfrost.com/computing_parameters_analytically/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Computing_Parameters_Analytically.ipynb
一. Normal Equation 1. 正规方程 正规方程法相对梯度下降法，它可以一步找到最小值。而且它也不需要进行特征值的缩放。
样本集是 $ m * n $ 的矩阵，每行样本表示为 $ \vec{x^{(i)}} $ ,第 i 行第 n 列分别表示为 $ x^{(i)}{0} , x^{(i)}{1} , x^{(i)}{2} , x^{(i)}{3} \cdots x^{(i)}_{n} $, m 行向量分别表示为 $ \vec{x^{(1)}} , \vec{x^{(2)}} , \vec{x^{(3)}} , \cdots \vec{x^{(m)}} $
令
$$ \vec{x^{(i)}} = \begin{bmatrix} x^{(i)}{0}\ x^{(i)}{1}\ \vdots \ x^{(i)}_{n}\ \end{bmatrix} $$</description></item><item><title>多元线性回归</title><link>https://new.halfrost.com/multivariate_linear_regression/</link><pubDate>Tue, 20 Mar 2018 07:47:00 +0000</pubDate><guid>https://new.halfrost.com/multivariate_linear_regression/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Multivariate_Linear_Regression.ipynb
一. Multiple Features 具有多个变量的线性回归也被称为“多元线性回归”。
$x_{j}^{(i)}$: 训练集第 i 个向量中的第 j 个元素(第 i 行第 j 列)
$x^{(i)}$: 训练集第 i 个向量(第 i 行)
$ m $: 总共 m 行
$ n $: 总共 n 列
适应这些多特征的假设函数的多变量形式如下：
$$ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \theta_{3}x_{3} + \cdots + \theta_{n}x_{n} $$
使用矩阵乘法的定义，我们的多变量假设函数可以简洁地表示为：</description></item><item><title>如何理解梯度下降？</title><link>https://new.halfrost.com/gradient_descent/</link><pubDate>Sun, 18 Mar 2018 21:54:00 +0000</pubDate><guid>https://new.halfrost.com/gradient_descent/</guid><description>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Gradient_descent.ipynb
一. Model Representation 在给定训练集的情况下，学习函数h：X→Y，使得h（x）是y的相应值的“好”预测器。由于历史原因，这个函数h被称为假设。
通过输入住房面积 x，通过学习好的函数，输出房子的估价。
二. Cost Function 代价函数是线性回归中的一个应用，在线性回归中，要解决的一个问题就是最小化问题。
假设在一元线性回归中，在一个训练集中，我们需要找到一条直线能和该训练集中的点最接近。假设直线方程为
$$h_{\theta}(x) = \theta_{0} + \theta_{1}x$$
如何选择 $\theta_{0}$、$\theta_{1}$，使得 $h_{\theta}(x)$ 更接近于训练集 (x,y) ？
上述问题可以转换为求 $$ \rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$ 求最小值$$\min_{{\theta_{0}} {\theta_{1}}} \rm{F}({\theta_{0},{\theta_{1}})} $$
三. Gradient Descent 梯度下降 梯度下降的主要思想：
初始化 ${\theta_{0}}$ 和 ${\theta_{1}}$ , ${\theta_{0}}$ = 0 , ${\theta_{1}}$ = 0 不断的改变 ${\theta_{0}}$ 和 ${\theta_{1}}$ 值，不断减少 $F({\theta_{0}},{\theta_{1}})$ 直至达到最小值（或者局部最小）。 想象成下山，如何下山的速度最快？这里涉及到了下山的速度，即步长。</description></item><item><title>什么是机器学习？</title><link>https://new.halfrost.com/what_is_machine_learning/</link><pubDate>Sun, 18 Mar 2018 06:30:00 +0000</pubDate><guid>https://new.halfrost.com/what_is_machine_learning/</guid><description>一. What is Machine Learning? 在机器学习的历史上，一共出现了两种定义。
1956 年，开发了西洋跳棋 AI 程序的 Arthur Samuel 在标志着人工智能学科诞生的达特茅斯会议上定义了 “机器学习” 这个词，定义为，“在没有明确设置的情况下，使计算机具有学习能力的研究领域”。
1997 年，Tom Mitchell 提供了一个更现代的定义：“如果用 P 来测量程序在任务 T 中性能。若一个程序通过利用经验 E 在 T 任务中获得了性能改善，则我们就说关于任务 T 和 性能测量 P ，该程序对经验 E 进行了学习。”
例如：玩跳棋。
E = 玩很多盘跳棋游戏的经验
T = 玩跳棋的任务。
P = 程序将赢得下一场比赛的概率。
二. Classify 一般来说，任何机器学习问题都可以分配到两大类中的一个：
有监督学习 supervised learning 和无监督学习 unsupervised learning。
简单的说，监督学习就是我们教计算机去做某件事情，无监督学习是我们让计算机自己学习。
1. supervised learning 在监督式学习中，首先有一个数据集，并且已知正确的输出是什么，且输入和输出存在关联。 监督学习问题分为“回归 Regression”和“分类 Classification”问题。
在回归问题中，我们试图预测连续输出中的结果，这意味着我们试图将输入变量映射到某个连续函数。例如给定一个人的照片，根据照片预测年龄，这就是一个回归的问题。
在分类问题中，我们试图预测离散输出中的结果。换句话说，我们试图将输入变量映射到离散类别中。例如给予患有肿瘤的患者，我们必须预测肿瘤是恶性的还是良性的。
2. unsupervised learning 无监督学习使我们能够很少或根本不知道我们的结果应该是什么样子。我们可以从数据中得出结构，我们不一定知道变量的影响。 我们可以通过基于数据中变量之间的关系对数据进行聚类来推导出这种结构。 在无监督学习的情况下，没有基于预测结果的反馈。无监督学习可以分为“聚类”和“非聚类”。</description></item></channel></rss>