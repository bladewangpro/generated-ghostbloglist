<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=theme-color content="#FFFFFF"><meta http-equiv=x-ua-compatible content="IE=edge"><title>什么是正则化？ | prometheus</title><meta name=description content="Explore in every moment of the hard thinking"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="什么是正则化？"><meta property="og:description" content="由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb
 一. Solving the Problem of Overfitting 考虑从 $x \in \mathbb{R}$ 预测 y 的问题。下面最左边的图显示了将 $y =\theta_{0}+\theta_{1}x$ 拟合到数据集的结果。我们看到这些数据并不是直线的，所以这个数据并不是很好。
相反，如果我们添加了一个额外的特征 x2，并且拟合 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}$，那么我们获得的数据稍微更适合,如上图。
但是并不是添加的多项式越多越好。但是，添加太多特征也是一个危险：最右边的数字是拟合五阶多项式 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}+\theta_{5}x^{5} $ 的结果。我们看到即使拟合曲线完美地传递了数据，我们也不会认为这是一个很好的预测，上图最右边的图就是过度拟合的例子。
上图最右边的图也称有高方差。如果我们拟合一个高阶多项式，有过度的特征，并且这个假设函数能拟合几乎所有的数据，这就面临可能的函数太过于庞大，变量太多的问题。我们没有足够的数据去约束它，来获得一个好的假设函数，这就是过度拟合。
欠拟合或高偏倚是当我们的假设函数h的形式很难与数据的趋势作图时。它通常是由一个功能太简单或功能太少造成的。另一方面，过度拟合或高度方差是由适合现有数据的假设函数引起的，但不能很好地预测新数据。它通常是由一个复杂的函数造成的，它会产生大量与数据无关的不必要的曲线和角度。
这个术语适用于线性和逻辑回归。解决过度配合问题有两个主要选项：
1. 减少特征的数量：  手动选择要保留的特征，哪些变量更为重要，哪些变量应该保留，哪些应该舍弃。 使用模型选择算法（稍后在课程中学习），算法会自动选择哪些特征变量保留，哪些舍弃。  缺点是舍弃了一些特征以后，也就舍弃了一些问题的关键信息。
2. 正则化  保留所有的特征，但减少参数 $\theta_{j}$ 的大小或者减少量级。 当有很多个特征的时候，并且每个特征都会对最终预测值产生影响，正则化可以保证运作良好。  正则化目的是尽量去简化这个假设模型。因为这些参数都接近0的时候，越简单的模型也被证明越不容易出现过拟合的问题。
减少一些数量级的特征，加一些“惩罚”项(为了使代价函数最小，乘以 1000 就是惩罚)。
代价函数：
$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{2m} \left [ \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 + \lambda \sum_{i = 1}^{m} \theta_{j}^{2} \right ]$$"><meta property="og:type" content="article"><meta property="og:url" content="https://new.halfrost.com/regularization/"><meta property="article:published_time" content="2018-03-23T08:16:00+00:00"><meta property="article:modified_time" content="2018-03-23T08:16:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="什么是正则化？"><meta name=twitter:description content="由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 Github 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。
GitHub Repo：Halfrost-Field
Follow: halfrost · GitHub
Source: https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb
 一. Solving the Problem of Overfitting 考虑从 $x \in \mathbb{R}$ 预测 y 的问题。下面最左边的图显示了将 $y =\theta_{0}+\theta_{1}x$ 拟合到数据集的结果。我们看到这些数据并不是直线的，所以这个数据并不是很好。
相反，如果我们添加了一个额外的特征 x2，并且拟合 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}$，那么我们获得的数据稍微更适合,如上图。
但是并不是添加的多项式越多越好。但是，添加太多特征也是一个危险：最右边的数字是拟合五阶多项式 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}+\theta_{5}x^{5} $ 的结果。我们看到即使拟合曲线完美地传递了数据，我们也不会认为这是一个很好的预测，上图最右边的图就是过度拟合的例子。
上图最右边的图也称有高方差。如果我们拟合一个高阶多项式，有过度的特征，并且这个假设函数能拟合几乎所有的数据，这就面临可能的函数太过于庞大，变量太多的问题。我们没有足够的数据去约束它，来获得一个好的假设函数，这就是过度拟合。
欠拟合或高偏倚是当我们的假设函数h的形式很难与数据的趋势作图时。它通常是由一个功能太简单或功能太少造成的。另一方面，过度拟合或高度方差是由适合现有数据的假设函数引起的，但不能很好地预测新数据。它通常是由一个复杂的函数造成的，它会产生大量与数据无关的不必要的曲线和角度。
这个术语适用于线性和逻辑回归。解决过度配合问题有两个主要选项：
1. 减少特征的数量：  手动选择要保留的特征，哪些变量更为重要，哪些变量应该保留，哪些应该舍弃。 使用模型选择算法（稍后在课程中学习），算法会自动选择哪些特征变量保留，哪些舍弃。  缺点是舍弃了一些特征以后，也就舍弃了一些问题的关键信息。
2. 正则化  保留所有的特征，但减少参数 $\theta_{j}$ 的大小或者减少量级。 当有很多个特征的时候，并且每个特征都会对最终预测值产生影响，正则化可以保证运作良好。  正则化目的是尽量去简化这个假设模型。因为这些参数都接近0的时候，越简单的模型也被证明越不容易出现过拟合的问题。
减少一些数量级的特征，加一些“惩罚”项(为了使代价函数最小，乘以 1000 就是惩罚)。
代价函数：
$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{2m} \left [ \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 + \lambda \sum_{i = 1}^{m} \theta_{j}^{2} \right ]$$"><link rel=stylesheet href=/css/style-white.min.css><link rel=manifest href=/manifest.json><link rel=stylesheet href=/prism.css><link href=/images/apple-touch-icon-60x60.png rel=apple-touch-icon sizes=60x60><link href=/images/apple-touch-icon-76x76.png rel=apple-touch-icon sizes=76x76><link href=/images/apple-touch-icon-120x120.png rel=apple-touch-icon sizes=120x120><link href=/images/apple-touch-icon-152x152.png rel=apple-touch-icon sizes=152x152><link href=/images/apple-touch-icon-180x180.png rel=apple-touch-icon sizes=180x180><link href=/images/apple-touch-icon-512x512.png rel=apple-touch-icon sizes=512x512><link href=/images/apple-touch-icon-1024x1024.png rel=apple-touch-icon sizes=1024x1024><script async>if('serviceWorker'in navigator){navigator.serviceWorker.register("\/serviceworker-v1.min.a64912b78d282eab1ad3715a0943da21616e5f326f8afea27034784ad445043b.js").then(function(){if(navigator.serviceWorker.controller){console.log('Assets cached by the controlling service worker.');}else{console.log('Please reload this page to allow the service worker to handle network operations.');}}).catch(function(error){console.log('ERROR: '+error);});}else{console.log('Service workers are not supported in the current browser.');}</script><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://new.halfrost.com/images/favicon.ico><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-82753806-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class="single-max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a><a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a><a id=top-icon-tablet href=# onclick="$('html, body').animate({scrollTop:0},'fast');" style=display:none><i class="fas fa-chevron-up fa-lg"></i></a><span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=https://books.halfrost.com/>Books</a></li><li><a href=https://github.com/halfrost/Halfrost-Field>Github</a></li><li><a href=https://halfrost.me/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://new.halfrost.com/logistic_regression/><i class="fas fa-chevron-left" aria-hidden=true onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li><li><a class=icon href=https://new.halfrost.com/neural_networks_representation/><i class="fas fa-chevron-right" aria-hidden=true onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li><li><a class=icon href=# onclick="$('html, body').animate({scrollTop:0},'fast');"><i class="fas fa-chevron-up" aria-hidden=true onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li><li><a class=icon href=#><i class="fas fa-share-alt" aria-hidden=true onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fnew.halfrost.com%2fregularization%2f"><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&text=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&is_video=false&description=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f&body=Check out this article: https%3a%2f%2fnew.halfrost.com%2fregularization%2f"><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-stumbleupon" aria-hidden=true></i></a></li><li><a class=icon href="http://digg.com/submit?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-digg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&name=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f&description=%e7%94%b1%e4%ba%8e%20Ghost%20%e5%8d%9a%e5%ae%a2%e5%af%b9%20LateX%20%e7%9a%84%e8%af%86%e5%88%ab%e8%af%ad%e6%b3%95%e5%92%8c%e6%a0%87%e5%87%86%e7%9a%84%20LateX%20%e8%af%ad%e6%b3%95%e6%9c%89%e5%b7%ae%e5%bc%82%ef%bc%8c%e4%b8%ba%e4%ba%86%e6%9b%b4%e5%8a%a0%e9%80%9a%e7%94%a8%e6%80%a7%ef%bc%8c%e6%89%80%e4%bb%a5%e4%bb%a5%e4%b8%8b%e6%96%87%e7%ab%a0%e4%b8%ad%20LateX%20%e5%85%ac%e5%bc%8f%e5%8f%af%e8%83%bd%e5%87%ba%e7%8e%b0%e4%b9%b1%e7%a0%81%ef%bc%8c%e5%a6%82%e6%9e%9c%e5%87%ba%e7%8e%b0%e4%b9%b1%e7%a0%81%ef%bc%8c%e4%b8%8d%e5%ab%8c%e5%bc%83%e7%9a%84%e8%af%9d%e5%8f%af%e4%bb%a5%e5%9c%a8%e7%ac%94%e8%80%85%e7%9a%84%20Github%20%e4%b8%8a%e7%9c%8b%e8%bf%99%e7%af%87%e6%97%a0%e4%b9%b1%e7%a0%81%e7%9a%84%e6%96%87%e7%ab%a0%e3%80%82%e7%ac%94%e8%80%85%e6%9c%89%e7%a9%ba%e4%bc%9a%e4%bf%ae%e5%a4%8d%e8%bf%99%e4%b8%aa%e4%b9%b1%e7%a0%81%e9%97%ae%e9%a2%98%e7%9a%84%e3%80%82%e8%af%b7%e8%a7%81%e8%b0%85%e3%80%82%0aGitHub%20Repo%ef%bc%9aHalfrost-Field%0aFollow%3a%20halfrost%20%c2%b7%20GitHub%0aSource%3a%20https%3a%2f%2fgithub.com%2fhalfrost%2fHalfrost-Field%2fblob%2fmaster%2fcontents%2fMachine_Learning%2fRegularization.ipynb%0a%20%e4%b8%80.%20Solving%20the%20Problem%20of%20Overfitting%20%e8%80%83%e8%99%91%e4%bb%8e%20%24x%20%5cin%20%5cmathbb%7bR%7d%24%20%e9%a2%84%e6%b5%8b%20y%20%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%e4%b8%8b%e9%9d%a2%e6%9c%80%e5%b7%a6%e8%be%b9%e7%9a%84%e5%9b%be%e6%98%be%e7%a4%ba%e4%ba%86%e5%b0%86%20%24y%20%3d%5ctheta_%7b0%7d%2b%5ctheta_%7b1%7dx%24%20%e6%8b%9f%e5%90%88%e5%88%b0%e6%95%b0%e6%8d%ae%e9%9b%86%e7%9a%84%e7%bb%93%e6%9e%9c%e3%80%82%e6%88%91%e4%bb%ac%e7%9c%8b%e5%88%b0%e8%bf%99%e4%ba%9b%e6%95%b0%e6%8d%ae%e5%b9%b6%e4%b8%8d%e6%98%af%e7%9b%b4%e7%ba%bf%e7%9a%84%ef%bc%8c%e6%89%80%e4%bb%a5%e8%bf%99%e4%b8%aa%e6%95%b0%e6%8d%ae%e5%b9%b6%e4%b8%8d%e6%98%af%e5%be%88%e5%a5%bd%e3%80%82%0a%e7%9b%b8%e5%8f%8d%ef%bc%8c%e5%a6%82%e6%9e%9c%e6%88%91%e4%bb%ac%e6%b7%bb%e5%8a%a0%e4%ba%86%e4%b8%80%e4%b8%aa%e9%a2%9d%e5%a4%96%e7%9a%84%e7%89%b9%e5%be%81%20x2%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%8b%9f%e5%90%88%20%24y%20%3d%5ctheta_%7b0%7d%2b%5ctheta_%7b1%7dx%2b%5ctheta_%7b2%7dx%5e%7b2%7d%24%ef%bc%8c%e9%82%a3%e4%b9%88%e6%88%91%e4%bb%ac%e8%8e%b7%e5%be%97%e7%9a%84%e6%95%b0%e6%8d%ae%e7%a8%8d%e5%be%ae%e6%9b%b4%e9%80%82%e5%90%88%2c%e5%a6%82%e4%b8%8a%e5%9b%be%e3%80%82%0a%e4%bd%86%e6%98%af%e5%b9%b6%e4%b8%8d%e6%98%af%e6%b7%bb%e5%8a%a0%e7%9a%84%e5%a4%9a%e9%a1%b9%e5%bc%8f%e8%b6%8a%e5%a4%9a%e8%b6%8a%e5%a5%bd%e3%80%82%e4%bd%86%e6%98%af%ef%bc%8c%e6%b7%bb%e5%8a%a0%e5%a4%aa%e5%a4%9a%e7%89%b9%e5%be%81%e4%b9%9f%e6%98%af%e4%b8%80%e4%b8%aa%e5%8d%b1%e9%99%a9%ef%bc%9a%e6%9c%80%e5%8f%b3%e8%be%b9%e7%9a%84%e6%95%b0%e5%ad%97%e6%98%af%e6%8b%9f%e5%90%88%e4%ba%94%e9%98%b6%e5%a4%9a%e9%a1%b9%e5%bc%8f%20%24y%20%3d%5ctheta_%7b0%7d%2b%5ctheta_%7b1%7dx%2b%5ctheta_%7b2%7dx%5e%7b2%7d%2b%5ctheta_%7b3%7dx%5e%7b3%7d%2b%5ctheta_%7b4%7dx%5e%7b4%7d%2b%5ctheta_%7b5%7dx%5e%7b5%7d%20%24%20%e7%9a%84%e7%bb%93%e6%9e%9c%e3%80%82%e6%88%91%e4%bb%ac%e7%9c%8b%e5%88%b0%e5%8d%b3%e4%bd%bf%e6%8b%9f%e5%90%88%e6%9b%b2%e7%ba%bf%e5%ae%8c%e7%be%8e%e5%9c%b0%e4%bc%a0%e9%80%92%e4%ba%86%e6%95%b0%e6%8d%ae%ef%bc%8c%e6%88%91%e4%bb%ac%e4%b9%9f%e4%b8%8d%e4%bc%9a%e8%ae%a4%e4%b8%ba%e8%bf%99%e6%98%af%e4%b8%80%e4%b8%aa%e5%be%88%e5%a5%bd%e7%9a%84%e9%a2%84%e6%b5%8b%ef%bc%8c%e4%b8%8a%e5%9b%be%e6%9c%80%e5%8f%b3%e8%be%b9%e7%9a%84%e5%9b%be%e5%b0%b1%e6%98%af%e8%bf%87%e5%ba%a6%e6%8b%9f%e5%90%88%e7%9a%84%e4%be%8b%e5%ad%90%e3%80%82%0a%e4%b8%8a%e5%9b%be%e6%9c%80%e5%8f%b3%e8%be%b9%e7%9a%84%e5%9b%be%e4%b9%9f%e7%a7%b0%e6%9c%89%e9%ab%98%e6%96%b9%e5%b7%ae%e3%80%82%e5%a6%82%e6%9e%9c%e6%88%91%e4%bb%ac%e6%8b%9f%e5%90%88%e4%b8%80%e4%b8%aa%e9%ab%98%e9%98%b6%e5%a4%9a%e9%a1%b9%e5%bc%8f%ef%bc%8c%e6%9c%89%e8%bf%87%e5%ba%a6%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e5%b9%b6%e4%b8%94%e8%bf%99%e4%b8%aa%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0%e8%83%bd%e6%8b%9f%e5%90%88%e5%87%a0%e4%b9%8e%e6%89%80%e6%9c%89%e7%9a%84%e6%95%b0%e6%8d%ae%ef%bc%8c%e8%bf%99%e5%b0%b1%e9%9d%a2%e4%b8%b4%e5%8f%af%e8%83%bd%e7%9a%84%e5%87%bd%e6%95%b0%e5%a4%aa%e8%bf%87%e4%ba%8e%e5%ba%9e%e5%a4%a7%ef%bc%8c%e5%8f%98%e9%87%8f%e5%a4%aa%e5%a4%9a%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%e6%88%91%e4%bb%ac%e6%b2%a1%e6%9c%89%e8%b6%b3%e5%a4%9f%e7%9a%84%e6%95%b0%e6%8d%ae%e5%8e%bb%e7%ba%a6%e6%9d%9f%e5%ae%83%ef%bc%8c%e6%9d%a5%e8%8e%b7%e5%be%97%e4%b8%80%e4%b8%aa%e5%a5%bd%e7%9a%84%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0%ef%bc%8c%e8%bf%99%e5%b0%b1%e6%98%af%e8%bf%87%e5%ba%a6%e6%8b%9f%e5%90%88%e3%80%82%0a%e6%ac%a0%e6%8b%9f%e5%90%88%e6%88%96%e9%ab%98%e5%81%8f%e5%80%9a%e6%98%af%e5%bd%93%e6%88%91%e4%bb%ac%e7%9a%84%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0h%e7%9a%84%e5%bd%a2%e5%bc%8f%e5%be%88%e9%9a%be%e4%b8%8e%e6%95%b0%e6%8d%ae%e7%9a%84%e8%b6%8b%e5%8a%bf%e4%bd%9c%e5%9b%be%e6%97%b6%e3%80%82%e5%ae%83%e9%80%9a%e5%b8%b8%e6%98%af%e7%94%b1%e4%b8%80%e4%b8%aa%e5%8a%9f%e8%83%bd%e5%a4%aa%e7%ae%80%e5%8d%95%e6%88%96%e5%8a%9f%e8%83%bd%e5%a4%aa%e5%b0%91%e9%80%a0%e6%88%90%e7%9a%84%e3%80%82%e5%8f%a6%e4%b8%80%e6%96%b9%e9%9d%a2%ef%bc%8c%e8%bf%87%e5%ba%a6%e6%8b%9f%e5%90%88%e6%88%96%e9%ab%98%e5%ba%a6%e6%96%b9%e5%b7%ae%e6%98%af%e7%94%b1%e9%80%82%e5%90%88%e7%8e%b0%e6%9c%89%e6%95%b0%e6%8d%ae%e7%9a%84%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0%e5%bc%95%e8%b5%b7%e7%9a%84%ef%bc%8c%e4%bd%86%e4%b8%8d%e8%83%bd%e5%be%88%e5%a5%bd%e5%9c%b0%e9%a2%84%e6%b5%8b%e6%96%b0%e6%95%b0%e6%8d%ae%e3%80%82%e5%ae%83%e9%80%9a%e5%b8%b8%e6%98%af%e7%94%b1%e4%b8%80%e4%b8%aa%e5%a4%8d%e6%9d%82%e7%9a%84%e5%87%bd%e6%95%b0%e9%80%a0%e6%88%90%e7%9a%84%ef%bc%8c%e5%ae%83%e4%bc%9a%e4%ba%a7%e7%94%9f%e5%a4%a7%e9%87%8f%e4%b8%8e%e6%95%b0%e6%8d%ae%e6%97%a0%e5%85%b3%e7%9a%84%e4%b8%8d%e5%bf%85%e8%a6%81%e7%9a%84%e6%9b%b2%e7%ba%bf%e5%92%8c%e8%a7%92%e5%ba%a6%e3%80%82%0a%e8%bf%99%e4%b8%aa%e6%9c%af%e8%af%ad%e9%80%82%e7%94%a8%e4%ba%8e%e7%ba%bf%e6%80%a7%e5%92%8c%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92%e3%80%82%e8%a7%a3%e5%86%b3%e8%bf%87%e5%ba%a6%e9%85%8d%e5%90%88%e9%97%ae%e9%a2%98%e6%9c%89%e4%b8%a4%e4%b8%aa%e4%b8%bb%e8%a6%81%e9%80%89%e9%a1%b9%ef%bc%9a%0a1.%20%e5%87%8f%e5%b0%91%e7%89%b9%e5%be%81%e7%9a%84%e6%95%b0%e9%87%8f%ef%bc%9a%20%20%e6%89%8b%e5%8a%a8%e9%80%89%e6%8b%a9%e8%a6%81%e4%bf%9d%e7%95%99%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e5%93%aa%e4%ba%9b%e5%8f%98%e9%87%8f%e6%9b%b4%e4%b8%ba%e9%87%8d%e8%a6%81%ef%bc%8c%e5%93%aa%e4%ba%9b%e5%8f%98%e9%87%8f%e5%ba%94%e8%af%a5%e4%bf%9d%e7%95%99%ef%bc%8c%e5%93%aa%e4%ba%9b%e5%ba%94%e8%af%a5%e8%88%8d%e5%bc%83%e3%80%82%20%e4%bd%bf%e7%94%a8%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9%e7%ae%97%e6%b3%95%ef%bc%88%e7%a8%8d%e5%90%8e%e5%9c%a8%e8%af%be%e7%a8%8b%e4%b8%ad%e5%ad%a6%e4%b9%a0%ef%bc%89%ef%bc%8c%e7%ae%97%e6%b3%95%e4%bc%9a%e8%87%aa%e5%8a%a8%e9%80%89%e6%8b%a9%e5%93%aa%e4%ba%9b%e7%89%b9%e5%be%81%e5%8f%98%e9%87%8f%e4%bf%9d%e7%95%99%ef%bc%8c%e5%93%aa%e4%ba%9b%e8%88%8d%e5%bc%83%e3%80%82%20%20%e7%bc%ba%e7%82%b9%e6%98%af%e8%88%8d%e5%bc%83%e4%ba%86%e4%b8%80%e4%ba%9b%e7%89%b9%e5%be%81%e4%bb%a5%e5%90%8e%ef%bc%8c%e4%b9%9f%e5%b0%b1%e8%88%8d%e5%bc%83%e4%ba%86%e4%b8%80%e4%ba%9b%e9%97%ae%e9%a2%98%e7%9a%84%e5%85%b3%e9%94%ae%e4%bf%a1%e6%81%af%e3%80%82%0a2.%20%e6%ad%a3%e5%88%99%e5%8c%96%20%20%e4%bf%9d%e7%95%99%e6%89%80%e6%9c%89%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e4%bd%86%e5%87%8f%e5%b0%91%e5%8f%82%e6%95%b0%20%24%5ctheta_%7bj%7d%24%20%e7%9a%84%e5%a4%a7%e5%b0%8f%e6%88%96%e8%80%85%e5%87%8f%e5%b0%91%e9%87%8f%e7%ba%a7%e3%80%82%20%e5%bd%93%e6%9c%89%e5%be%88%e5%a4%9a%e4%b8%aa%e7%89%b9%e5%be%81%e7%9a%84%e6%97%b6%e5%80%99%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%af%8f%e4%b8%aa%e7%89%b9%e5%be%81%e9%83%bd%e4%bc%9a%e5%af%b9%e6%9c%80%e7%bb%88%e9%a2%84%e6%b5%8b%e5%80%bc%e4%ba%a7%e7%94%9f%e5%bd%b1%e5%93%8d%ef%bc%8c%e6%ad%a3%e5%88%99%e5%8c%96%e5%8f%af%e4%bb%a5%e4%bf%9d%e8%af%81%e8%bf%90%e4%bd%9c%e8%89%af%e5%a5%bd%e3%80%82%20%20%e6%ad%a3%e5%88%99%e5%8c%96%e7%9b%ae%e7%9a%84%e6%98%af%e5%b0%bd%e9%87%8f%e5%8e%bb%e7%ae%80%e5%8c%96%e8%bf%99%e4%b8%aa%e5%81%87%e8%ae%be%e6%a8%a1%e5%9e%8b%e3%80%82%e5%9b%a0%e4%b8%ba%e8%bf%99%e4%ba%9b%e5%8f%82%e6%95%b0%e9%83%bd%e6%8e%a5%e8%bf%910%e7%9a%84%e6%97%b6%e5%80%99%ef%bc%8c%e8%b6%8a%e7%ae%80%e5%8d%95%e7%9a%84%e6%a8%a1%e5%9e%8b%e4%b9%9f%e8%a2%ab%e8%af%81%e6%98%8e%e8%b6%8a%e4%b8%8d%e5%ae%b9%e6%98%93%e5%87%ba%e7%8e%b0%e8%bf%87%e6%8b%9f%e5%90%88%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%0a%e5%87%8f%e5%b0%91%e4%b8%80%e4%ba%9b%e6%95%b0%e9%87%8f%e7%ba%a7%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e5%8a%a0%e4%b8%80%e4%ba%9b%e2%80%9c%e6%83%a9%e7%bd%9a%e2%80%9d%e9%a1%b9%28%e4%b8%ba%e4%ba%86%e4%bd%bf%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0%e6%9c%80%e5%b0%8f%ef%bc%8c%e4%b9%98%e4%bb%a5%201000%20%e5%b0%b1%e6%98%af%e6%83%a9%e7%bd%9a%29%e3%80%82%0a%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0%ef%bc%9a%0a%24%24%20%5crm%7bCostFunction%7d%20%3d%20%5crm%7bF%7d%28%7b%5ctheta%7d%29%20%3d%20%5cfrac%7b1%7d%7b2m%7d%20%5cleft%20%5b%20%5csum_%7bi%20%3d%201%7d%5e%7bm%7d%20%28h_%7b%5ctheta%7d%28x%5e%7b%28i%29%7d%29-y%5e%7b%28i%29%7d%29%5e2%20%2b%20%5clambda%20%5csum_%7bi%20%3d%201%7d%5e%7bm%7d%20%5ctheta_%7bj%7d%5e%7b2%7d%20%5cright%20%5d%24%24"><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&t=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#一-solving-the-problem-of-overfitting>一. Solving the Problem of Overfitting</a><ul><li><a href=#1-减少特征的数量>1. 减少特征的数量：</a></li><li><a href=#2-正则化>2. 正则化</a></li></ul></li><li><a href=#二-regularized-linear-regression-线性回归正则化>二. Regularized Linear Regression 线性回归正则化</a><ul><li><a href=#1-gradient-descent-线性回归梯度下降正则化>1. Gradient Descent 线性回归梯度下降正则化</a></li><li><a href=#2-normal-equation-线性回归正规方程正则化>2. Normal Equation 线性回归正规方程正则化</a></li></ul></li><li><a href=#三-regularized-logistic-regression-逻辑回归正则化>三. Regularized Logistic Regression 逻辑回归正则化</a><ul><li><a href=#1-gradient-descent-逻辑回归梯度下降正则化>1. Gradient Descent 逻辑回归梯度下降正则化</a></li></ul></li><li><a href=#四-regularization-测试>四. Regularization 测试</a><ul><li><a href=#1-question-1>1. Question 1</a></li><li><a href=#2-question-2>2. Question 2</a></li><li><a href=#3-question-3>3. Question 3</a></li></ul></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">什么是正则化？</h1><div class=meta><div class=postdate><time datetime="2018-03-23 08:16:00 +0000 UTC" itemprop=datePublished>Mar 23</time></div><div class=article-category><i class="fas fa-archive"></i><a class=category-link href=/categories/machine-learning>Machine Learning</a>
,
<a class=category-link href=/categories/ai>AI</a></div><div class=article-tag><i class="fas fa-tag"></i><a class=tag-link href=/tags/machine-learning rel=tag>Machine Learning</a>
,
<a class=tag-link href=/tags/ai rel=tag>AI</a></div></div></header><div class=content itemprop=articleBody><blockquote><p>由于 Ghost 博客对 LateX 的识别语法和标准的 LateX 语法有差异，为了更加通用性，所以以下文章中 LateX 公式可能出现乱码，如果出现乱码，不嫌弃的话可以在笔者的 <a href=https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/contents.md>Github</a> 上看这篇无乱码的文章。笔者有空会修复这个乱码问题的。请见谅。</p><p>GitHub Repo：<a href=https://github.com/halfrost/Halfrost-Field>Halfrost-Field</a><br>Follow: <a href=https://github.com/halfrost>halfrost · GitHub</a><br>Source: <a href=https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb>https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb</a></p></blockquote><h2 id=一-solving-the-problem-of-overfitting>一. Solving the Problem of Overfitting</h2><p>考虑从 $x \in \mathbb{R}$ 预测 y 的问题。下面最左边的图显示了将 $y =\theta_{0}+\theta_{1}x$ 拟合到数据集的结果。我们看到这些数据并不是直线的，所以这个数据并不是很好。</p><p><img src=https://img.halfrost.com/Blog/ArticleImage/70_2.png alt></p><p>相反，如果我们添加了一个额外的特征 x2，并且拟合 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}$，那么我们获得的数据稍微更适合,如上图。</p><p>但是并不是添加的多项式越多越好。但是，添加太多特征也是一个危险：最右边的数字是拟合五阶多项式 $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}+\theta_{5}x^{5} $ 的结果。我们看到即使拟合曲线完美地传递了数据，我们也不会认为这是一个很好的预测，上图最右边的图就是过度拟合的例子。</p><p>上图最右边的图也称有<strong>高方差</strong>。如果我们拟合一个高阶多项式，有过度的特征，并且这个假设函数能拟合几乎所有的数据，这就面临可能的函数太过于庞大，变量太多的问题。我们没有足够的数据去约束它，来获得一个好的假设函数，这就是过度拟合。</p><p>欠拟合或高偏倚是当我们的假设函数h的形式很难与数据的趋势作图时。它通常是由一个功能太简单或功能太少造成的。另一方面，过度拟合或高度方差是由适合现有数据的假设函数引起的，但不能很好地预测新数据。它通常是由一个复杂的函数造成的，它会产生大量与数据无关的不必要的曲线和角度。</p><p><img src=https://img.halfrost.com/Blog/ArticleImage/70_3.png alt></p><p>这个术语适用于线性和逻辑回归。解决过度配合问题有两个主要选项：</p><h3 id=1-减少特征的数量>1. 减少特征的数量：</h3><ul><li>手动选择要保留的特征，哪些变量更为重要，哪些变量应该保留，哪些应该舍弃。</li><li>使用模型选择算法（稍后在课程中学习），算法会自动选择哪些特征变量保留，哪些舍弃。</li></ul><p>缺点是舍弃了一些特征以后，也就舍弃了一些问题的关键信息。</p><h3 id=2-正则化>2. 正则化</h3><ul><li>保留所有的特征，但减少参数 $\theta_{j}$ 的大小或者减少量级。</li><li>当有很多个特征的时候，并且每个特征都会对最终预测值产生影响，正则化可以保证运作良好。</li></ul><p>正则化目的是尽量去简化这个假设模型。因为这些参数都接近0的时候，越简单的模型也被证明越不容易出现过拟合的问题。</p><p><img src=https://img.halfrost.com/Blog/ArticleImage/70_4.png alt></p><p>减少一些数量级的特征，加一些“惩罚”项(为了使代价函数最小，乘以 1000 就是惩罚)。</p><p>代价函数：</p><p>$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{2m} \left [ \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 + \lambda \sum_{i = 1}^{m} \theta_{j}^{2} \right ]$$</p><p>$\lambda \sum_{i = 1}^{m} \theta_{j}^{2}$ 是正则化项，它缩小每个参数的值。 $\lambda$ 是正则化参数，$\lambda$ 控制两个不同目标之间的取舍，即更好的去拟合训练集的目标 和 将参数控制的更小的目标，从而保持假设模型的相对简单，避免出现过拟合的情况。</p><p>但是如果选择的 $\lambda $ 太大，可能会过多地消除特征，导致 $\theta$ 都约等于 0 了，最终预测函数变成了水平直线了。这就变成了欠拟合的例子了(偏见性太强，偏差过高)。</p><hr><h2 id=二-regularized-linear-regression-线性回归正则化>二. Regularized Linear Regression 线性回归正则化</h2><h3 id=1-gradient-descent-线性回归梯度下降正则化>1. Gradient Descent 线性回归梯度下降正则化</h3><p>$$\theta_{0} := \theta_{0} - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)}$$</p><p>$$\theta_{j} := \theta_{j} - \alpha \left [ \left ( \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}\right ) + \frac{\lambda}{m}\theta_{j} \right ] ;;;;;;;;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix}$$</p><p>将上面的式子化简得：</p><p>$$\theta_{j} := \theta_{j}(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)} ;;;;;;;;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix}$$</p><p>在上面的式子中 $(1-\alpha \frac{\lambda}{m}) &lt; 1$ 恒小于 1，约等于 1(0.999) 。于是梯度下降的过程就是每次更新都把参数乘以 0.999，缩小一点点，然后再向最小点的方向移动一下。</p><h3 id=2-normal-equation-线性回归正规方程正则化>2. Normal Equation 线性回归正规方程正则化</h3><p>之前推导过的正规方程结论：</p><p>$$\Theta = (X^{T}X)^{-1}X^{T}Y$$</p><p>正则化以后，上述式子变成了：</p><p>$$\Theta = \left( X^{T}X +\lambda \begin{bmatrix}
0 & & & & \
& 1 & & & \
& & 1 & & \
& & & \ddots & \
& & & & 1
\end{bmatrix} \right) ^{-1}X^{T}Y$$</p><p>在之前的讨论中，有一个<strong>前提条件是 $X^{T}X$ 是非奇异(非退化)矩阵， 即 $ \left | X^{T}X \right | \neq 0 $</strong></p><p>在上述正则化的式子里面，只要 $\lambda > 0$，就不存在不可逆的问题了。因为 $\left( X^{T}X +\lambda \begin{bmatrix}
0 & & & & \
& 1 & & & \
& & 1 & & \
& & & \ddots & \
& & & & 1
\end{bmatrix} \right)$ 这一项一定是可逆的，因为它一定不是奇异矩阵。所以<strong>正则化还能解决不可逆的情况</strong>。</p><hr><h2 id=三-regularized-logistic-regression-逻辑回归正则化>三. Regularized Logistic Regression 逻辑回归正则化</h2><p><img src=https://img.halfrost.com/Blog/ArticleImage/70_5.png alt></p><p>之前讨论过的代价函数是：</p><p>$$
\begin{align*}
\rm{CostFunction} = \rm{F}({\theta}) &= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] \<br>\left( h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} \right )
\end{align*}
$$</p><p>正则化以后：</p><p>$$
\begin{align*}
\rm{CostFunction} = \rm{F}({\theta}) &= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] +\frac{\lambda}{2m} \sum_{j=1}^{n}\theta_{j}^{2} \<br>\end{align*}
$$</p><h3 id=1-gradient-descent-逻辑回归梯度下降正则化>1. Gradient Descent 逻辑回归梯度下降正则化</h3><p>式子等同于线性回归正则化</p><p>$$
\begin{align*}
\theta_{0} &:= \theta_{0} - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)} ;;;;;;;;;;;;;;;;;;;;;j = 1 \<br>\theta_{j} &:= \theta_{j}(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)} ;;;;;;;;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix} \<br>\end{align*}
$$</p><p>虽然式子和线性回归的一模一样，不过这里的 $h_{\theta}(x)$ 代表的意义不同，逻辑回归中：</p><p>$$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}}$$</p><hr><h2 id=四-regularization-测试>四. Regularization 测试</h2><h3 id=1-question-1>1. Question 1</h3><p>You are training a classification model with logistic regression. Which of the following statements are true? Check all that apply.</p><p>A. Introducing regularization to the model always results in equal or better performance on the training set.</p><p>B. Introducing regularization to the model always results in equal or better performance on examples not in the training set.</p><p>C. Adding many new features to the model makes it more likely to overfit the training set.</p><p>D. Adding a new feature to the model always results in equal or better performance on examples not in the training set.</p><p>解答： D</p><p>A、B 正则化的引入是解决过拟合的问题，而过拟合正是过度拟合数据但无法泛化到新的数据样本中。<br>D 增加一些特征量可能导致拟合在训练集原本没有被拟合到的数据，正确，这就是过拟合。</p><h3 id=2-question-2>2. Question 2</h3><p>Suppose you ran logistic regression twice, once with λ=0, and once with λ=1. One of the times, you got</p><p>parameters $\theta = \begin{bmatrix}
26.29\
65.41
\end{bmatrix}$, and the other time you got $\theta = \begin{bmatrix}
2.75\
1.32
\end{bmatrix}$. However, you forgot which value of λ corresponds to which value of θ. Which one do you think corresponds to λ=1?</p><p>A. $\theta = \begin{bmatrix}
26.29\
65.41
\end{bmatrix}$</p><p>B. $\theta = \begin{bmatrix}
2.75\
1.32
\end{bmatrix}$</p><p>解答： B</p><p>$\lambda = 1$表示正则化以后。正则化其实让我们的 $\theta_j$变小，所以选B。</p><h3 id=3-question-3>3. Question 3</h3><p>Which of the following statements about regularization are true? Check all that apply.</p><p>A. Using too large a value of λ can cause your hypothesis to overfit the data; this can be avoided by reducing λ.</p><p>B. Consider a classification problem. Adding regularization may cause your classifier to incorrectly classify some training examples (which it had correctly classified when not using regularization, i.e. when λ=0).</p><p>C. Because logistic regression outputs values 0≤hθ(x)≤1, its range of output values can only be &ldquo;shrunk&rdquo; slightly by regularization anyway, so regularization is generally not helpful for it.</p><p>D. Using a very large value of λ cannot hurt the performance of your hypothesis; the only reason we do not set λ to be too large is to avoid numerical problems.</p><p>解答： B</p><p>C 正则化对逻辑回归没用，错误。<br>A、D $\lambda$过大会导致欠拟合。</p><hr><blockquote><p>GitHub Repo：<a href=https://github.com/halfrost/Halfrost-Field>Halfrost-Field</a></p><p>Follow: <a href=https://github.com/halfrost>halfrost · GitHub</a></p><p>Source: <a href=https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb>https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb</a></p></blockquote><img src=https://img.halfrost.com/wechat-qr-code.png></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=https://books.halfrost.com/>Books</a></li><li><a href=https://github.com/halfrost/Halfrost-Field>Github</a></li><li><a href=https://halfrost.me/>About</a></li><li><a href=/index.xml>RSS</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#一-solving-the-problem-of-overfitting>一. Solving the Problem of Overfitting</a><ul><li><a href=#1-减少特征的数量>1. 减少特征的数量：</a></li><li><a href=#2-正则化>2. 正则化</a></li></ul></li><li><a href=#二-regularized-linear-regression-线性回归正则化>二. Regularized Linear Regression 线性回归正则化</a><ul><li><a href=#1-gradient-descent-线性回归梯度下降正则化>1. Gradient Descent 线性回归梯度下降正则化</a></li><li><a href=#2-normal-equation-线性回归正规方程正则化>2. Normal Equation 线性回归正规方程正则化</a></li></ul></li><li><a href=#三-regularized-logistic-regression-逻辑回归正则化>三. Regularized Logistic Regression 逻辑回归正则化</a><ul><li><a href=#1-gradient-descent-逻辑回归梯度下降正则化>1. Gradient Descent 逻辑回归梯度下降正则化</a></li></ul></li><li><a href=#四-regularization-测试>四. Regularization 测试</a><ul><li><a href=#1-question-1>1. Question 1</a></li><li><a href=#2-question-2>2. Question 2</a></li><li><a href=#3-question-3>3. Question 3</a></li></ul></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fnew.halfrost.com%2fregularization%2f"><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&text=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&is_video=false&description=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f&body=Check out this article: https%3a%2f%2fnew.halfrost.com%2fregularization%2f"><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.stumbleupon.com/submit?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-stumbleupon fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://digg.com/submit?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&title=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-digg fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&name=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f&description=%e7%94%b1%e4%ba%8e%20Ghost%20%e5%8d%9a%e5%ae%a2%e5%af%b9%20LateX%20%e7%9a%84%e8%af%86%e5%88%ab%e8%af%ad%e6%b3%95%e5%92%8c%e6%a0%87%e5%87%86%e7%9a%84%20LateX%20%e8%af%ad%e6%b3%95%e6%9c%89%e5%b7%ae%e5%bc%82%ef%bc%8c%e4%b8%ba%e4%ba%86%e6%9b%b4%e5%8a%a0%e9%80%9a%e7%94%a8%e6%80%a7%ef%bc%8c%e6%89%80%e4%bb%a5%e4%bb%a5%e4%b8%8b%e6%96%87%e7%ab%a0%e4%b8%ad%20LateX%20%e5%85%ac%e5%bc%8f%e5%8f%af%e8%83%bd%e5%87%ba%e7%8e%b0%e4%b9%b1%e7%a0%81%ef%bc%8c%e5%a6%82%e6%9e%9c%e5%87%ba%e7%8e%b0%e4%b9%b1%e7%a0%81%ef%bc%8c%e4%b8%8d%e5%ab%8c%e5%bc%83%e7%9a%84%e8%af%9d%e5%8f%af%e4%bb%a5%e5%9c%a8%e7%ac%94%e8%80%85%e7%9a%84%20Github%20%e4%b8%8a%e7%9c%8b%e8%bf%99%e7%af%87%e6%97%a0%e4%b9%b1%e7%a0%81%e7%9a%84%e6%96%87%e7%ab%a0%e3%80%82%e7%ac%94%e8%80%85%e6%9c%89%e7%a9%ba%e4%bc%9a%e4%bf%ae%e5%a4%8d%e8%bf%99%e4%b8%aa%e4%b9%b1%e7%a0%81%e9%97%ae%e9%a2%98%e7%9a%84%e3%80%82%e8%af%b7%e8%a7%81%e8%b0%85%e3%80%82%0aGitHub%20Repo%ef%bc%9aHalfrost-Field%0aFollow%3a%20halfrost%20%c2%b7%20GitHub%0aSource%3a%20https%3a%2f%2fgithub.com%2fhalfrost%2fHalfrost-Field%2fblob%2fmaster%2fcontents%2fMachine_Learning%2fRegularization.ipynb%0a%20%e4%b8%80.%20Solving%20the%20Problem%20of%20Overfitting%20%e8%80%83%e8%99%91%e4%bb%8e%20%24x%20%5cin%20%5cmathbb%7bR%7d%24%20%e9%a2%84%e6%b5%8b%20y%20%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%e4%b8%8b%e9%9d%a2%e6%9c%80%e5%b7%a6%e8%be%b9%e7%9a%84%e5%9b%be%e6%98%be%e7%a4%ba%e4%ba%86%e5%b0%86%20%24y%20%3d%5ctheta_%7b0%7d%2b%5ctheta_%7b1%7dx%24%20%e6%8b%9f%e5%90%88%e5%88%b0%e6%95%b0%e6%8d%ae%e9%9b%86%e7%9a%84%e7%bb%93%e6%9e%9c%e3%80%82%e6%88%91%e4%bb%ac%e7%9c%8b%e5%88%b0%e8%bf%99%e4%ba%9b%e6%95%b0%e6%8d%ae%e5%b9%b6%e4%b8%8d%e6%98%af%e7%9b%b4%e7%ba%bf%e7%9a%84%ef%bc%8c%e6%89%80%e4%bb%a5%e8%bf%99%e4%b8%aa%e6%95%b0%e6%8d%ae%e5%b9%b6%e4%b8%8d%e6%98%af%e5%be%88%e5%a5%bd%e3%80%82%0a%e7%9b%b8%e5%8f%8d%ef%bc%8c%e5%a6%82%e6%9e%9c%e6%88%91%e4%bb%ac%e6%b7%bb%e5%8a%a0%e4%ba%86%e4%b8%80%e4%b8%aa%e9%a2%9d%e5%a4%96%e7%9a%84%e7%89%b9%e5%be%81%20x2%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%8b%9f%e5%90%88%20%24y%20%3d%5ctheta_%7b0%7d%2b%5ctheta_%7b1%7dx%2b%5ctheta_%7b2%7dx%5e%7b2%7d%24%ef%bc%8c%e9%82%a3%e4%b9%88%e6%88%91%e4%bb%ac%e8%8e%b7%e5%be%97%e7%9a%84%e6%95%b0%e6%8d%ae%e7%a8%8d%e5%be%ae%e6%9b%b4%e9%80%82%e5%90%88%2c%e5%a6%82%e4%b8%8a%e5%9b%be%e3%80%82%0a%e4%bd%86%e6%98%af%e5%b9%b6%e4%b8%8d%e6%98%af%e6%b7%bb%e5%8a%a0%e7%9a%84%e5%a4%9a%e9%a1%b9%e5%bc%8f%e8%b6%8a%e5%a4%9a%e8%b6%8a%e5%a5%bd%e3%80%82%e4%bd%86%e6%98%af%ef%bc%8c%e6%b7%bb%e5%8a%a0%e5%a4%aa%e5%a4%9a%e7%89%b9%e5%be%81%e4%b9%9f%e6%98%af%e4%b8%80%e4%b8%aa%e5%8d%b1%e9%99%a9%ef%bc%9a%e6%9c%80%e5%8f%b3%e8%be%b9%e7%9a%84%e6%95%b0%e5%ad%97%e6%98%af%e6%8b%9f%e5%90%88%e4%ba%94%e9%98%b6%e5%a4%9a%e9%a1%b9%e5%bc%8f%20%24y%20%3d%5ctheta_%7b0%7d%2b%5ctheta_%7b1%7dx%2b%5ctheta_%7b2%7dx%5e%7b2%7d%2b%5ctheta_%7b3%7dx%5e%7b3%7d%2b%5ctheta_%7b4%7dx%5e%7b4%7d%2b%5ctheta_%7b5%7dx%5e%7b5%7d%20%24%20%e7%9a%84%e7%bb%93%e6%9e%9c%e3%80%82%e6%88%91%e4%bb%ac%e7%9c%8b%e5%88%b0%e5%8d%b3%e4%bd%bf%e6%8b%9f%e5%90%88%e6%9b%b2%e7%ba%bf%e5%ae%8c%e7%be%8e%e5%9c%b0%e4%bc%a0%e9%80%92%e4%ba%86%e6%95%b0%e6%8d%ae%ef%bc%8c%e6%88%91%e4%bb%ac%e4%b9%9f%e4%b8%8d%e4%bc%9a%e8%ae%a4%e4%b8%ba%e8%bf%99%e6%98%af%e4%b8%80%e4%b8%aa%e5%be%88%e5%a5%bd%e7%9a%84%e9%a2%84%e6%b5%8b%ef%bc%8c%e4%b8%8a%e5%9b%be%e6%9c%80%e5%8f%b3%e8%be%b9%e7%9a%84%e5%9b%be%e5%b0%b1%e6%98%af%e8%bf%87%e5%ba%a6%e6%8b%9f%e5%90%88%e7%9a%84%e4%be%8b%e5%ad%90%e3%80%82%0a%e4%b8%8a%e5%9b%be%e6%9c%80%e5%8f%b3%e8%be%b9%e7%9a%84%e5%9b%be%e4%b9%9f%e7%a7%b0%e6%9c%89%e9%ab%98%e6%96%b9%e5%b7%ae%e3%80%82%e5%a6%82%e6%9e%9c%e6%88%91%e4%bb%ac%e6%8b%9f%e5%90%88%e4%b8%80%e4%b8%aa%e9%ab%98%e9%98%b6%e5%a4%9a%e9%a1%b9%e5%bc%8f%ef%bc%8c%e6%9c%89%e8%bf%87%e5%ba%a6%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e5%b9%b6%e4%b8%94%e8%bf%99%e4%b8%aa%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0%e8%83%bd%e6%8b%9f%e5%90%88%e5%87%a0%e4%b9%8e%e6%89%80%e6%9c%89%e7%9a%84%e6%95%b0%e6%8d%ae%ef%bc%8c%e8%bf%99%e5%b0%b1%e9%9d%a2%e4%b8%b4%e5%8f%af%e8%83%bd%e7%9a%84%e5%87%bd%e6%95%b0%e5%a4%aa%e8%bf%87%e4%ba%8e%e5%ba%9e%e5%a4%a7%ef%bc%8c%e5%8f%98%e9%87%8f%e5%a4%aa%e5%a4%9a%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%e6%88%91%e4%bb%ac%e6%b2%a1%e6%9c%89%e8%b6%b3%e5%a4%9f%e7%9a%84%e6%95%b0%e6%8d%ae%e5%8e%bb%e7%ba%a6%e6%9d%9f%e5%ae%83%ef%bc%8c%e6%9d%a5%e8%8e%b7%e5%be%97%e4%b8%80%e4%b8%aa%e5%a5%bd%e7%9a%84%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0%ef%bc%8c%e8%bf%99%e5%b0%b1%e6%98%af%e8%bf%87%e5%ba%a6%e6%8b%9f%e5%90%88%e3%80%82%0a%e6%ac%a0%e6%8b%9f%e5%90%88%e6%88%96%e9%ab%98%e5%81%8f%e5%80%9a%e6%98%af%e5%bd%93%e6%88%91%e4%bb%ac%e7%9a%84%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0h%e7%9a%84%e5%bd%a2%e5%bc%8f%e5%be%88%e9%9a%be%e4%b8%8e%e6%95%b0%e6%8d%ae%e7%9a%84%e8%b6%8b%e5%8a%bf%e4%bd%9c%e5%9b%be%e6%97%b6%e3%80%82%e5%ae%83%e9%80%9a%e5%b8%b8%e6%98%af%e7%94%b1%e4%b8%80%e4%b8%aa%e5%8a%9f%e8%83%bd%e5%a4%aa%e7%ae%80%e5%8d%95%e6%88%96%e5%8a%9f%e8%83%bd%e5%a4%aa%e5%b0%91%e9%80%a0%e6%88%90%e7%9a%84%e3%80%82%e5%8f%a6%e4%b8%80%e6%96%b9%e9%9d%a2%ef%bc%8c%e8%bf%87%e5%ba%a6%e6%8b%9f%e5%90%88%e6%88%96%e9%ab%98%e5%ba%a6%e6%96%b9%e5%b7%ae%e6%98%af%e7%94%b1%e9%80%82%e5%90%88%e7%8e%b0%e6%9c%89%e6%95%b0%e6%8d%ae%e7%9a%84%e5%81%87%e8%ae%be%e5%87%bd%e6%95%b0%e5%bc%95%e8%b5%b7%e7%9a%84%ef%bc%8c%e4%bd%86%e4%b8%8d%e8%83%bd%e5%be%88%e5%a5%bd%e5%9c%b0%e9%a2%84%e6%b5%8b%e6%96%b0%e6%95%b0%e6%8d%ae%e3%80%82%e5%ae%83%e9%80%9a%e5%b8%b8%e6%98%af%e7%94%b1%e4%b8%80%e4%b8%aa%e5%a4%8d%e6%9d%82%e7%9a%84%e5%87%bd%e6%95%b0%e9%80%a0%e6%88%90%e7%9a%84%ef%bc%8c%e5%ae%83%e4%bc%9a%e4%ba%a7%e7%94%9f%e5%a4%a7%e9%87%8f%e4%b8%8e%e6%95%b0%e6%8d%ae%e6%97%a0%e5%85%b3%e7%9a%84%e4%b8%8d%e5%bf%85%e8%a6%81%e7%9a%84%e6%9b%b2%e7%ba%bf%e5%92%8c%e8%a7%92%e5%ba%a6%e3%80%82%0a%e8%bf%99%e4%b8%aa%e6%9c%af%e8%af%ad%e9%80%82%e7%94%a8%e4%ba%8e%e7%ba%bf%e6%80%a7%e5%92%8c%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92%e3%80%82%e8%a7%a3%e5%86%b3%e8%bf%87%e5%ba%a6%e9%85%8d%e5%90%88%e9%97%ae%e9%a2%98%e6%9c%89%e4%b8%a4%e4%b8%aa%e4%b8%bb%e8%a6%81%e9%80%89%e9%a1%b9%ef%bc%9a%0a1.%20%e5%87%8f%e5%b0%91%e7%89%b9%e5%be%81%e7%9a%84%e6%95%b0%e9%87%8f%ef%bc%9a%20%20%e6%89%8b%e5%8a%a8%e9%80%89%e6%8b%a9%e8%a6%81%e4%bf%9d%e7%95%99%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e5%93%aa%e4%ba%9b%e5%8f%98%e9%87%8f%e6%9b%b4%e4%b8%ba%e9%87%8d%e8%a6%81%ef%bc%8c%e5%93%aa%e4%ba%9b%e5%8f%98%e9%87%8f%e5%ba%94%e8%af%a5%e4%bf%9d%e7%95%99%ef%bc%8c%e5%93%aa%e4%ba%9b%e5%ba%94%e8%af%a5%e8%88%8d%e5%bc%83%e3%80%82%20%e4%bd%bf%e7%94%a8%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9%e7%ae%97%e6%b3%95%ef%bc%88%e7%a8%8d%e5%90%8e%e5%9c%a8%e8%af%be%e7%a8%8b%e4%b8%ad%e5%ad%a6%e4%b9%a0%ef%bc%89%ef%bc%8c%e7%ae%97%e6%b3%95%e4%bc%9a%e8%87%aa%e5%8a%a8%e9%80%89%e6%8b%a9%e5%93%aa%e4%ba%9b%e7%89%b9%e5%be%81%e5%8f%98%e9%87%8f%e4%bf%9d%e7%95%99%ef%bc%8c%e5%93%aa%e4%ba%9b%e8%88%8d%e5%bc%83%e3%80%82%20%20%e7%bc%ba%e7%82%b9%e6%98%af%e8%88%8d%e5%bc%83%e4%ba%86%e4%b8%80%e4%ba%9b%e7%89%b9%e5%be%81%e4%bb%a5%e5%90%8e%ef%bc%8c%e4%b9%9f%e5%b0%b1%e8%88%8d%e5%bc%83%e4%ba%86%e4%b8%80%e4%ba%9b%e9%97%ae%e9%a2%98%e7%9a%84%e5%85%b3%e9%94%ae%e4%bf%a1%e6%81%af%e3%80%82%0a2.%20%e6%ad%a3%e5%88%99%e5%8c%96%20%20%e4%bf%9d%e7%95%99%e6%89%80%e6%9c%89%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e4%bd%86%e5%87%8f%e5%b0%91%e5%8f%82%e6%95%b0%20%24%5ctheta_%7bj%7d%24%20%e7%9a%84%e5%a4%a7%e5%b0%8f%e6%88%96%e8%80%85%e5%87%8f%e5%b0%91%e9%87%8f%e7%ba%a7%e3%80%82%20%e5%bd%93%e6%9c%89%e5%be%88%e5%a4%9a%e4%b8%aa%e7%89%b9%e5%be%81%e7%9a%84%e6%97%b6%e5%80%99%ef%bc%8c%e5%b9%b6%e4%b8%94%e6%af%8f%e4%b8%aa%e7%89%b9%e5%be%81%e9%83%bd%e4%bc%9a%e5%af%b9%e6%9c%80%e7%bb%88%e9%a2%84%e6%b5%8b%e5%80%bc%e4%ba%a7%e7%94%9f%e5%bd%b1%e5%93%8d%ef%bc%8c%e6%ad%a3%e5%88%99%e5%8c%96%e5%8f%af%e4%bb%a5%e4%bf%9d%e8%af%81%e8%bf%90%e4%bd%9c%e8%89%af%e5%a5%bd%e3%80%82%20%20%e6%ad%a3%e5%88%99%e5%8c%96%e7%9b%ae%e7%9a%84%e6%98%af%e5%b0%bd%e9%87%8f%e5%8e%bb%e7%ae%80%e5%8c%96%e8%bf%99%e4%b8%aa%e5%81%87%e8%ae%be%e6%a8%a1%e5%9e%8b%e3%80%82%e5%9b%a0%e4%b8%ba%e8%bf%99%e4%ba%9b%e5%8f%82%e6%95%b0%e9%83%bd%e6%8e%a5%e8%bf%910%e7%9a%84%e6%97%b6%e5%80%99%ef%bc%8c%e8%b6%8a%e7%ae%80%e5%8d%95%e7%9a%84%e6%a8%a1%e5%9e%8b%e4%b9%9f%e8%a2%ab%e8%af%81%e6%98%8e%e8%b6%8a%e4%b8%8d%e5%ae%b9%e6%98%93%e5%87%ba%e7%8e%b0%e8%bf%87%e6%8b%9f%e5%90%88%e7%9a%84%e9%97%ae%e9%a2%98%e3%80%82%0a%e5%87%8f%e5%b0%91%e4%b8%80%e4%ba%9b%e6%95%b0%e9%87%8f%e7%ba%a7%e7%9a%84%e7%89%b9%e5%be%81%ef%bc%8c%e5%8a%a0%e4%b8%80%e4%ba%9b%e2%80%9c%e6%83%a9%e7%bd%9a%e2%80%9d%e9%a1%b9%28%e4%b8%ba%e4%ba%86%e4%bd%bf%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0%e6%9c%80%e5%b0%8f%ef%bc%8c%e4%b9%98%e4%bb%a5%201000%20%e5%b0%b1%e6%98%af%e6%83%a9%e7%bd%9a%29%e3%80%82%0a%e4%bb%a3%e4%bb%b7%e5%87%bd%e6%95%b0%ef%bc%9a%0a%24%24%20%5crm%7bCostFunction%7d%20%3d%20%5crm%7bF%7d%28%7b%5ctheta%7d%29%20%3d%20%5cfrac%7b1%7d%7b2m%7d%20%5cleft%20%5b%20%5csum_%7bi%20%3d%201%7d%5e%7bm%7d%20%28h_%7b%5ctheta%7d%28x%5e%7b%28i%29%7d%29-y%5e%7b%28i%29%7d%29%5e2%20%2b%20%5clambda%20%5csum_%7bi%20%3d%201%7d%5e%7bm%7d%20%5ctheta_%7bj%7d%5e%7b2%7d%20%5cright%20%5d%24%24"><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fnew.halfrost.com%2fregularization%2f&t=%e4%bb%80%e4%b9%88%e6%98%af%e6%ad%a3%e5%88%99%e5%8c%96%ef%bc%9f"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu class=icon href=# onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden=true></i>Menu</a>
<a id=toc class=icon href=# onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden=true></i>TOC</a>
<a id=share class=icon href=# onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden=true></i>share</a>
<a id=top style=display:none class=icon href=# onclick="$('html, body').animate({scrollTop:0},'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i>Top</a></div></div></div><footer id=footer><div class=footer-left><p class=copyright style=float:left;margin-bottom:0><a href=https://github.com/halfrost/Halfrost-Field class=github-repo style=height:18px><span class=gadget-github></span>Star</a>
Copyright &copy;halfrost 2016 - 2021
<a href=http://www.miit.gov.cn/>鄂ICP备16014744号</a></p><br><p class="copyright statistics" style=margin-bottom:20px><span id=busuanzi_container_site_pv>Cumulative Page Views <span id=busuanzi_value_site_pv></span>| Unique Visitors <span id=busuanzi_value_site_uv></span></span></p></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script><script src=/main.min.f870a4d110314b9e50e65f8ac982dc1c9c376c8f1a5083d39c62cfc49073f011.js></script><script async src=/prism.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}};</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>